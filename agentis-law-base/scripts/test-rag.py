#!/usr/bin/env python3
"""
Test RAG: search Pinecone for relevant articles given sample contract text.

Run:
  export OPENAI_API_KEY=sk-...
  export PINECONE_API_KEY=pcsk_...
  python3 scripts/test-rag.py
"""

import json, os, sys, urllib.request, urllib.error

OPENAI_KEY = os.environ.get('OPENAI_API_KEY', '')
PINECONE_KEY = os.environ.get('PINECONE_API_KEY', '')
PINECONE_HOST = os.environ.get('PINECONE_HOST', '')  # will auto-detect
NAMESPACE = 'ua-law-v1'


def http_json(method, url, body=None, headers=None):
    hdrs = {'Content-Type': 'application/json'}
    if headers: hdrs.update(headers)
    data = json.dumps(body).encode('utf-8') if body else None
    req = urllib.request.Request(url, data=data, headers=hdrs, method=method)
    with urllib.request.urlopen(req, timeout=30) as resp:
        return json.loads(resp.read().decode('utf-8'))


def get_host():
    if PINECONE_HOST: return PINECONE_HOST
    indexes = http_json('GET', 'https://api.pinecone.io/indexes', headers={'Api-Key': PINECONE_KEY})
    idx = next((i for i in (indexes.get('indexes') or []) if i['name'] == 'agentis-law'), None)
    if not idx: raise Exception('Index not found')
    return f"https://{idx['host']}"


def embed(text):
    res = http_json('POST', 'https://api.openai.com/v1/embeddings',
        body={'model': 'text-embedding-3-small', 'input': text},
        headers={'Authorization': f'Bearer {OPENAI_KEY}'})
    return res['data'][0]['embedding']


def search(host, vector, top_k=10):
    res = http_json('POST', f'{host}/query',
        body={'vector': vector, 'topK': top_k, 'includeMetadata': True, 'namespace': NAMESPACE},
        headers={'Api-Key': PINECONE_KEY})
    return res.get('matches', [])


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#  TEST CASES
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

TESTS = [
    {
        'name': 'üè† –î–æ–≥–æ–≤—ñ—Ä –æ—Ä–µ–Ω–¥–∏ –∫–≤–∞—Ä—Ç–∏—Ä–∏',
        'text': '''–î–æ–≥–æ–≤—ñ—Ä –æ—Ä–µ–Ω–¥–∏ –∂–∏—Ç–ª–æ–≤–æ–≥–æ –ø—Ä–∏–º—ñ—â–µ–Ω–Ω—è. 
        –û—Ä–µ–Ω–¥–æ–¥–∞–≤–µ—Ü—å –ø–µ—Ä–µ–¥–∞—î, –∞ –û—Ä–µ–Ω–¥–∞—Ä –ø—Ä–∏–π–º–∞—î —É —Ç–∏–º—á–∞—Å–æ–≤–µ –ø–ª–∞—Ç–Ω–µ –∫–æ—Ä–∏—Å—Ç—É–≤–∞–Ω–Ω—è –∫–≤–∞—Ä—Ç–∏—Ä—É. 
        –û—Ä–µ–Ω–¥–Ω–∞ –ø–ª–∞—Ç–∞ —Å–∫–ª–∞–¥–∞—î 15000 –≥—Ä–Ω –Ω–∞ –º—ñ—Å—è—Ü—å. –°—Ç—Ä–æ–∫ –æ—Ä–µ–Ω–¥–∏ 12 –º—ñ—Å—è—Ü—ñ–≤.
        –û—Ä–µ–Ω–¥–∞—Ä –∑–æ–±–æ–≤\'—è–∑–∞–Ω–∏–π —Å–≤–æ—î—á–∞—Å–Ω–æ —Å–ø–ª–∞—á—É–≤–∞—Ç–∏ –æ—Ä–µ–Ω–¥–Ω—É –ø–ª–∞—Ç—É —Ç–∞ –∫–æ–º—É–Ω–∞–ª—å–Ω—ñ –ø–æ—Å–ª—É–≥–∏.''',
        'expect': ['lease', '–æ—Ä–µ–Ω–¥', '–Ω–∞–π–º'],
    },
    {
        'name': 'üë∑ –¢—Ä—É–¥–æ–≤–∏–π –¥–æ–≥–æ–≤—ñ—Ä',
        'text': '''–¢—Ä—É–¥–æ–≤–∏–π –¥–æ–≥–æ–≤—ñ—Ä. –†–æ–±–æ—Ç–æ–¥–∞–≤–µ—Ü—å –ø—Ä–∏–π–º–∞—î –ü—Ä–∞—Ü—ñ–≤–Ω–∏–∫–∞ –Ω–∞ –ø–æ—Å–∞–¥—É –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∑ –ø—Ä–æ–¥–∞–∂—É.
        –í–∏–ø—Ä–æ–±—É–≤–∞–ª—å–Ω–∏–π —Å—Ç—Ä–æ–∫ 3 –º—ñ—Å—è—Ü—ñ. –ó–∞—Ä–æ–±—ñ—Ç–Ω–∞ –ø–ª–∞—Ç–∞ 25000 –≥—Ä–Ω.
        –†–µ–∂–∏–º —Ä–æ–±–æ—Ç–∏: –ø–æ–Ω–µ–¥—ñ–ª–æ–∫-–ø\'—è—Ç–Ω–∏—Ü—è, –∑ 9:00 –¥–æ 18:00.
        –ü—Ä–∞—Ü—ñ–≤–Ω–∏–∫ –º–∞—î –ø—Ä–∞–≤–æ –Ω–∞ —â–æ—Ä—ñ—á–Ω—É –≤—ñ–¥–ø—É—Å—Ç–∫—É 24 –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–∏—Ö –¥–Ω—ñ.''',
        'expect': ['employment', '—Ç—Ä—É–¥–æ–≤', '–ö–ó–ø–ü'],
    },
    {
        'name': 'üõí –î–æ–≥–æ–≤—ñ—Ä –∫—É–ø—ñ–≤–ª—ñ-–ø—Ä–æ–¥–∞–∂—É',
        'text': '''–î–æ–≥–æ–≤—ñ—Ä –∫—É–ø—ñ–≤–ª—ñ-–ø—Ä–æ–¥–∞–∂—É —Ç–æ–≤–∞—Ä—É. –ü—Ä–æ–¥–∞–≤–µ—Ü—å –∑–æ–±–æ–≤\'—è–∑—É—î—Ç—å—Å—è –ø–µ—Ä–µ–¥–∞—Ç–∏ —É –≤–ª–∞—Å–Ω—ñ—Å—Ç—å 
        –ü–æ–∫—É–ø—Ü—è —Ç–æ–≤–∞—Ä, –∞ –ü–æ–∫—É–ø–µ—Ü—å –∑–æ–±–æ–≤\'—è–∑—É—î—Ç—å—Å—è –ø—Ä–∏–π–Ω—è—Ç–∏ —Ç–æ–≤–∞—Ä —Ç–∞ –æ–ø–ª–∞—Ç–∏—Ç–∏ –π–æ–≥–æ –≤–∞—Ä—Ç—ñ—Å—Ç—å.
        –¶—ñ–Ω–∞ —Ç–æ–≤–∞—Ä—É 500000 –≥—Ä–Ω. –î–æ—Å—Ç–∞–≤–∫–∞ –∑–∞ —Ä–∞—Ö—É–Ω–æ–∫ –ü—Ä–æ–¥–∞–≤—Ü—è.
        –ì–∞—Ä–∞–Ω—Ç—ñ–π–Ω–∏–π —Å—Ç—Ä–æ–∫ 12 –º—ñ—Å—è—Ü—ñ–≤ –∑ –¥–∞—Ç–∏ –ø–æ—Å—Ç–∞–≤–∫–∏.''',
        'expect': ['sale', '–∫—É–ø—ñ–≤–ª', '–ø—Ä–æ–¥–∞–∂'],
    },
]


def main():
    print('=' * 50)
    print('  AGENTIS RAG ‚Äî Test Search')
    print('=' * 50)

    host = get_host()
    print(f'Pinecone: {host}\n')

    for test in TESTS:
        print(f'\n{test["name"]}')
        print('-' * 50)

        # Embed query
        vector = embed(test['text'])

        # Search
        matches = search(host, vector, top_k=10)

        if not matches:
            print('  ‚ùå No results!')
            continue

        print(f'  Top 10 results (score = cosine similarity):\n')
        for m in matches:
            meta = m.get('metadata', {})
            score = m.get('score', 0)
            code = meta.get('code', '?')
            art_num = meta.get('article_number', '?')
            title = meta.get('title', '')[:60]
            importance = meta.get('importance', '')
            categories = meta.get('categories', '')

            icon = 'üî¥' if importance == 'critical' else 'üü°' if importance == 'high' else '‚ö™'
            print(f'  {icon} {score:.3f}  {code} —Å—Ç.{art_num} ‚Äî {title}')
            print(f'          [{categories}]')

        # Check expectations
        all_text = ' '.join(
            f"{m.get('metadata',{}).get('code','')} {m.get('metadata',{}).get('title','')} {m.get('metadata',{}).get('categories','')}"
            for m in matches[:5]
        ).lower()
        
        found = [e for e in test['expect'] if e.lower() in all_text]
        if found:
            print(f'\n  ‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ –æ—á—ñ–∫—É–≤–∞–Ω–µ: {found}')
        else:
            print(f'\n  ‚ö†Ô∏è  –û—á—ñ–∫—É–≤–∞–ª–æ—Å—å: {test["expect"]}')


if __name__ == '__main__':
    main()
